{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completing `bust_probability` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import sklearn\n",
    "from sklearn import metrics as metrics\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path, table_idx, player_or_dealer):\n",
    "    #utility for loading train.csv, example use in the notebook\n",
    "    data = pd.read_csv(path, header=[0,1,2])\n",
    "    spy = data[(f'table_{table_idx}', player_or_dealer, 'spy')]\n",
    "    card = data[(f'table_{table_idx}', player_or_dealer, 'card')]\n",
    "    return np.array([spy, card]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bust_probability(dealer_cards):\n",
    "    \"\"\"\n",
    "    dealer_cards: list -> integer series of player denoting value of cards observed upto this point\n",
    "\n",
    "    Current body is random for now, change it accordingly\n",
    "    \n",
    "    output: probability of going bust on this table\n",
    "    \"\"\"\n",
    "    bust_count = 0\n",
    "    total_cards = len(dealer_cards)\n",
    "    score = 0\n",
    "    for card in dealer_cards:\n",
    "        score += card\n",
    "        if score > 16:\n",
    "            if score > 21:\n",
    "                bust_count += 1\n",
    "            score = 0\n",
    "    return bust_count/total_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.18865\n",
      "1 0.10155\n",
      "2 0.09175\n",
      "3 0.07995\n",
      "4 0.00055\n"
     ]
    }
   ],
   "source": [
    "for table_idx in range(0, 5):\n",
    "    dealer_data = data_loader(\"data/train.csv\", table_idx, \"dealer\")\n",
    "    dealer_cards = dealer_data[:,1]\n",
    "    print(table_idx, bust_probability(dealer_cards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two additional points for \"willingness to play\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Effective House Edge (EHE)**  \n",
    "#### **Definition:**  \n",
    "This metric estimates the actual house edge at a given table based on observed outcomes rather than theoretical expectations. It measures the average percentage of a player’s bet lost per round.  \n",
    "\n",
    "#### **Formula:**  \n",
    "$$\n",
    "EHE = 1 - \\frac{\\text{Total player winnings}}{\\text{Total player bets}}\n",
    "$$\n",
    "where:  \n",
    "- **Total player winnings** = sum of all amounts won by players.  \n",
    "- **Total player bets** = sum of all bets placed by players.  \n",
    "\n",
    "#### **Strengths:**  \n",
    "- Captures the real-world profitability of a table.  \n",
    "- Accounts for both dealer performance and player behavior.  \n",
    "\n",
    "#### **Weaknesses:**  \n",
    "- Requires tracking actual bet sizes and payouts.  \n",
    "- Can be skewed if a few players make bad decisions.  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Volatility Score (VS)**  \n",
    "#### **Definition:**  \n",
    "Measures how unpredictable the dealer’s bust rate is across different hands.  \n",
    "A high volatility score suggests that the dealer’s performance is inconsistent.\n",
    "\n",
    "#### **Formula:**  \n",
    "$$\n",
    "VS = \\sigma_b = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (B_i - \\mu_b)^2}\n",
    "$$\n",
    "where:  \n",
    "- \\( $B_i$ \\) is the bust probability observed in past hands.  \n",
    "- \\( $\\mu_b$ \\) is the mean bust probability.  \n",
    "- \\( $\\sigma_b$ \\) is the standard deviation of bust probabilities.\n",
    "\n",
    "#### **Strengths:**  \n",
    "- Identifies tables with consistent dealer behavior (lower volatility is preferable).  \n",
    "- Helps risk-averse players avoid unpredictable situations.\n",
    "\n",
    "#### **Weaknesses:**  \n",
    "- Doesn’t directly indicate profitability.  \n",
    "- Requires enough historical data for accurate estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_value_from_spy_value(value : float) -> int:\n",
    "    \"\"\"\n",
    "    Implement here. Please make sure that the output of this function is an integer.\n",
    "    \"\"\"\n",
    "    value += 100\n",
    "    value += 2.5\n",
    "    value = math.trunc(value)\n",
    "    value = value % 10\n",
    "    if value <= 1:\n",
    "        value += 10\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "We observed the card values for various spy values for each of the table indices. We divided the array based on the card values, and saw the spy values for each card index (we also sorted the spy values). From this, we were able to observe the pattern of jump of 10 for each card index, and also the bound of 0.5 range. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sklearn\n",
    "from sklearn import metrics as metrics\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def data_loader(path, table_idx, player_or_dealer):\n",
    "    \"\"\"Loads the data for that table index.\"\"\"\n",
    "    data = pd.read_csv(path, header=[0,1,2])\n",
    "    spy = data[(f'table_{table_idx}', player_or_dealer, 'spy')]\n",
    "    card = data[(f'table_{table_idx}', player_or_dealer, 'card')]\n",
    "    return np.array([spy, card]).T\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Simple NN Architecture\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=16):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class MyPlayer:\n",
    "    def __init__(self, table_index):\n",
    "        self.table_index = table_index\n",
    "        self.player_model = None\n",
    "        self.dealer_model = None\n",
    "        self.player_model_type = None\n",
    "        self.dealer_model_type = None\n",
    "        self.player_scaler = None\n",
    "        self.dealer_scaler = None\n",
    "        self._load_or_train_models()\n",
    "    \n",
    "    def _load_or_train_models(self):\n",
    "        \"\"\"Load pre-trained models or train new ones\"\"\"\n",
    "        train_file = 'train.csv' \n",
    "        player_model_path = f'player_model_table_{self.table_index}.pkl'\n",
    "        dealer_model_path = f'dealer_model_table_{self.table_index}.pkl'\n",
    "        player_scaler_path = f'player_scaler_table_{self.table_index}.pkl'\n",
    "        dealer_scaler_path = f'dealer_scaler_table_{self.table_index}.pkl'\n",
    "        player_type_path = f'player_type_table_{self.table_index}.txt'\n",
    "        dealer_type_path = f'dealer_type_table_{self.table_index}.txt'\n",
    "        if os.path.exists(player_model_path) and os.path.exists(dealer_model_path):\n",
    "            with open(player_model_path, 'rb') as f:\n",
    "                self.player_model = pickle.load(f)\n",
    "            with open(player_type_path, 'r') as f:\n",
    "                self.player_model_type = f.read().strip()\n",
    "            if os.path.exists(player_scaler_path):\n",
    "                with open(player_scaler_path, 'rb') as f:\n",
    "                    self.player_scaler = pickle.load(f)\n",
    "            with open(dealer_model_path, 'rb') as f:\n",
    "                self.dealer_model = pickle.load(f)\n",
    "            with open(dealer_type_path, 'r') as f:\n",
    "                self.dealer_model_type = f.read().strip()\n",
    "            if os.path.exists(dealer_scaler_path):\n",
    "                with open(dealer_scaler_path, 'rb') as f:\n",
    "                    self.dealer_scaler = pickle.load(f)\n",
    "        else:\n",
    "            if os.path.exists(train_file):\n",
    "                self._train_models(train_file)\n",
    "            else:\n",
    "                self.player_model_type = 'linear'\n",
    "                self.dealer_model_type = 'linear'\n",
    "                self.player_model = LinearRegression()\n",
    "                self.dealer_model = LinearRegression()\n",
    "    \n",
    "    def _train_models(self, train_file):\n",
    "        \"\"\"Train models using data from train.csv\"\"\"\n",
    "        try:\n",
    "            data = pd.read_csv(train_file, header=[0, 1, 2])\n",
    "            player_spy = data[(f'table_{self.table_index}', 'player', 'spy')].values\n",
    "            dealer_spy = data[(f'table_{self.table_index}', 'dealer', 'spy')].values\n",
    "            X_player, y_player = self._create_sequence_data(player_spy)\n",
    "            X_dealer, y_dealer = self._create_sequence_data(dealer_spy)\n",
    "            player_model_info = self._select_and_train_best_model(X_player, y_player, 'player')\n",
    "            dealer_model_info = self._select_and_train_best_model(X_dealer, y_dealer, 'dealer')\n",
    "            self.player_model = player_model_info['model']\n",
    "            self.player_model_type = player_model_info['type']\n",
    "            self.player_scaler = player_model_info.get('scaler')\n",
    "            self.dealer_model = dealer_model_info['model']\n",
    "            self.dealer_model_type = dealer_model_info['type']\n",
    "            self.dealer_scaler = dealer_model_info.get('scaler')\n",
    "            self._save_models()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {e}\")\n",
    "            self.player_model_type = 'linear'\n",
    "            self.dealer_model_type = 'linear'\n",
    "            self.player_model = LinearRegression()\n",
    "            self.dealer_model = LinearRegression()\n",
    "    \n",
    "    def _create_sequence_data(self, series, lag=5):\n",
    "        \"\"\"Create sequence data with lag features for time series prediction\"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(lag, len(series)):\n",
    "            X.append(series[i-lag:i])\n",
    "            y.append(series[i])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def _select_and_train_best_model(self, X, y, role):\n",
    "        \"\"\"Select and train the best model for the data based on simple validation\"\"\"\n",
    "        if len(X) < 20:\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "            return {'model': model, 'type': 'linear'}\n",
    "        split = int(0.8 * len(X))\n",
    "        X_train, X_val = X[:split], X[split:]\n",
    "        y_train, y_val = y[:split], y[split:]\n",
    "        models = {\n",
    "            'linear': LinearRegression(),\n",
    "            'forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "            'nn': None\n",
    "        }\n",
    "        \n",
    "        best_mse = float('inf')\n",
    "        best_model_info = None\n",
    "        for model_type, model in models.items():\n",
    "            if model_type == 'nn':\n",
    "                continue\n",
    "                \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            mse = np.mean((y_val - y_pred) ** 2)\n",
    "            \n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_model_info = {'model': model, 'type': model_type}\n",
    "        if len(X_train) > 50:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_val_scaled = scaler.transform(X_val)\n",
    "            X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "            y_train_tensor = torch.FloatTensor(y_train.reshape(-1, 1))\n",
    "            X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "            model = SimpleNN(X_train.shape[1])\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "            epochs = 200\n",
    "            for epoch in range(epochs):\n",
    "                outputs = model(X_train_tensor)\n",
    "                loss = criterion(outputs, y_train_tensor)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(X_val_tensor).numpy().flatten()\n",
    "            mse = np.mean((y_val - y_pred) ** 2)\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_model_info = {'model': model, 'type': 'nn', 'scaler': scaler}\n",
    "        if best_model_info['type'] == 'nn':\n",
    "            X_scaled = best_model_info['scaler'].fit_transform(X)\n",
    "            X_tensor = torch.FloatTensor(X_scaled)\n",
    "            y_tensor = torch.FloatTensor(y.reshape(-1, 1))\n",
    "            model = SimpleNN(X.shape[1])\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "            epochs = 300\n",
    "            for epoch in range(epochs):\n",
    "                outputs = model(X_tensor)\n",
    "                loss = criterion(outputs, y_tensor)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            best_model_info['model'] = model\n",
    "        else:\n",
    "            best_model_info['model'].fit(X, y)\n",
    "        \n",
    "        return best_model_info\n",
    "    \n",
    "    def _save_models(self):\n",
    "        \"\"\"Save trained models to disk\"\"\"\n",
    "        with open(f'player_model_table_{self.table_index}.pkl', 'wb') as f:\n",
    "            pickle.dump(self.player_model, f)\n",
    "        with open(f'player_type_table_{self.table_index}.txt', 'w') as f:\n",
    "            f.write(self.player_model_type)\n",
    "        if self.player_scaler is not None:\n",
    "            with open(f'player_scaler_table_{self.table_index}.pkl', 'wb') as f:\n",
    "                pickle.dump(self.player_scaler, f)\n",
    "        with open(f'dealer_model_table_{self.table_index}.pkl', 'wb') as f:\n",
    "            pickle.dump(self.dealer_model, f)\n",
    "        with open(f'dealer_type_table_{self.table_index}.txt', 'w') as f:\n",
    "            f.write(self.dealer_model_type)\n",
    "        if self.dealer_scaler is not None:\n",
    "            with open(f'dealer_scaler_table_{self.table_index}.pkl', 'wb') as f:\n",
    "                pickle.dump(self.dealer_scaler, f)\n",
    "    \n",
    "    def get_card_value_from_spy_value(self, value):\n",
    "        \"\"\"\n",
    "        value: a value from the spy series as a float\n",
    "        Output: return a scalar value of the prediction\n",
    "        \"\"\"\n",
    "        value += 100\n",
    "        value += 2.5\n",
    "        value = math.trunc(value)\n",
    "        value = value % 10\n",
    "        if value <= 1:\n",
    "            value += 10\n",
    "        return value\n",
    "    \n",
    "    def get_player_spy_prediction(self, hist):\n",
    "        \"\"\"\n",
    "        hist: a 1D numpy array of size (len_history,) len_history=5\n",
    "        Output: return a scalar value of the prediction\n",
    "        \"\"\"\n",
    "        X = hist.reshape(1, -1)\n",
    "        if self.player_model_type == 'nn':\n",
    "            X_scaled = self.player_scaler.transform(X)\n",
    "            X_tensor = torch.FloatTensor(X_scaled)\n",
    "            self.player_model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = self.player_model(X_tensor).item()\n",
    "        else:\n",
    "            prediction = self.player_model.predict(X)[0]\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def get_dealer_spy_prediction(self, hist):\n",
    "        \"\"\"\n",
    "        hist: a 1D numpy array of size (len_history,) len_history=5\n",
    "        Output: return a scalar value of the prediction\n",
    "        \"\"\"\n",
    "        X = hist.reshape(1, -1)\n",
    "        if self.dealer_model_type == 'nn':\n",
    "            X_scaled = self.dealer_scaler.transform(X)\n",
    "            X_tensor = torch.FloatTensor(X_scaled)\n",
    "            self.dealer_model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = self.dealer_model(X_tensor).item()\n",
    "        else:\n",
    "            prediction = self.dealer_model.predict(X)[0] \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
